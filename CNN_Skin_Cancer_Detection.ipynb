{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhogasena/Skin_Cancer_Detection_CNN/blob/main/CNN_Skin_Cancer_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDriIbfa5lwD"
      },
      "source": [
        "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvR7ppk77v31"
      },
      "source": [
        "### Importing Skin Cancer Data\n",
        "#### To do: Take necessary actions to read the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      },
      "source": [
        "### Importing all the important libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WC8xCQuELWms"
      },
      "source": [
        "import pathlib\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import glob\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code is to authenticate with other Google Driver account"
      ],
      "metadata": {
        "id": "Ux0Am7Q1c0gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo echo -ne '\\n' | sudo add-apt-repository ppa:alessandro-strada/ppa >/dev/null 2>&1 # note: >/dev/null 2>&1 is used to supress printing\n",
        "# !sudo apt update >/dev/null 2>&1\n",
        "# !sudo apt install google-drive-ocamlfuse >/dev/null 2>&1\n",
        "# !google-drive-ocamlfuse\n",
        "# !sudo apt-get install w3m >/dev/null 2>&1 # to act as web browser \n",
        "# !xdg-settings set default-web-browser w3m.desktop >/dev/null 2>&1 # to set default browser \n",
        "# %cd /content\n",
        "# !mkdir gdrive\n",
        "# %cd gdrive\n",
        "# !mkdir \"My Drive\"\n",
        "# !google-drive-ocamlfuse \"/content/gdrive/My Drive\""
      ],
      "metadata": {
        "id": "dp_dwHdWro0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount with Google drive and download the dataset"
      ],
      "metadata": {
        "id": "229YYF9hc59Y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYpVPmT5z7AP"
      },
      "source": [
        "# # Mount to google drive and download the dataset\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip  '/content/gdrive/My Drive/CNN/CNN_assignment.zip' -d '/content/'\n",
        "os.rename('/content/Skin cancer ISIC The International Skin Imaging Collaboration','/content/DataSet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpUsRQwOOL72"
      },
      "source": [
        "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D57L-ovIKtI4"
      },
      "source": [
        "# Defining the path for train and test images\n",
        "## Todo: Update the paths of the train and test dataset\n",
        "data_dir_train = pathlib.Path(\"/content/DataSet/Train\")\n",
        "data_dir_test = pathlib.Path('/content/DataSet/Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqksN1w5Fu-N"
      },
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
        "print(image_count_train)\n",
        "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
        "print(image_count_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8HkfW3jPJun"
      },
      "source": [
        "### Load using keras.preprocessing\n",
        "\n",
        "Let's load these images off disk using the helpful image_dataset_from_directory utility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBKZG3jPcMc"
      },
      "source": [
        "### Create a dataset\n",
        "\n",
        "Define some parameters for the loader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLfcXcZ9LjGv"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5f5y43GPog1"
      },
      "source": [
        "Use 80% of the images for training, and 20% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1BWmDzr7w-5"
      },
      "source": [
        "# Create a Train Dataset\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_width,img_height),\n",
        "    validation_split=0.2,\n",
        "    subset='training'   \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYch6-SR-i2g"
      },
      "source": [
        "# Create a Validation Dataset\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir_train,\n",
        "    seed=123,\n",
        "    batch_size=batch_size,\n",
        "    image_size=(img_width,img_height),\n",
        "    validation_split=0.2,\n",
        "    subset='validation'   \n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk0RV7G7-nad"
      },
      "source": [
        "# List out all the classes of skin cancer and store them in a list. \n",
        "\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbsm5oYiQH_b"
      },
      "source": [
        "### Visualize the data for all 9 Skin classes\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,12))\n",
        "for i in range(len(class_names)):\n",
        "    filtered_ds = train_ds.filter(lambda image, label: tf.math.equal(label[0], i))\n",
        "    for image, label in filtered_ds.take(1):\n",
        "        ax = plt.subplot(3, 3, i+1)\n",
        "        plt.imshow(image[0].numpy().astype('uint8'))\n",
        "        plt.title(class_names[label[0]])\n",
        "        plt.axis('off')"
      ],
      "metadata": {
        "id": "hiLF1xxJzrLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cAZPYaeQjQy"
      },
      "source": [
        "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzVXBHiyQ7_I"
      },
      "source": [
        "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
        "\n",
        "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wZlKRBEGNtU"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEAF6-sRyz8"
      },
      "source": [
        "# Model1: Without Dropouts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ync9xoW7GZgn"
      },
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDKzJmHwSCtt"
      },
      "source": [
        "### Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB8wKtiPGe1j"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZGWN4MZGhtJ"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljD_83rwSl5O"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkfw2rJXGlYC"
      },
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3679V8OShSE"
      },
      "source": [
        "### Visualizing training results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1xkgk5nGubz"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvPphJYuSZhK"
      },
      "source": [
        "#### Observations\n",
        "\n",
        "As per above Accuracy and Loss graphs, we can clearly see that there is overfitting is present in the model as Training accuracy keeps increasing above 90% and where as validation accuracy got saturated around 50%.\n",
        "\n",
        "Training loss is getting lower and lower on each poch but where as validaiton loss has high variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22hljAl6GykA"
      },
      "source": [
        "# Todo, after you have analysed the model fit history for presence of underfit or overfit, choose an appropriate data augumentation strategy. \n",
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEjPWh8GG0C7"
      },
      "source": [
        "# Todo, visualize how your augmentation strategy works for one instance of training image.\n",
        "# Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKDHlUdTuSX"
      },
      "source": [
        "# Model 2: With Dropouts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3V4l-O9G3dM"
      },
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(256,kernel_regularizer=l2(0.9)))\n",
        "model.add(Dense(128,kernel_regularizer=l2(0.5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfUWFp96UIAN"
      },
      "source": [
        "### Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-7yTm8IG8zR"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC-D_RWOURp6"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcPfkUASHBf9"
      },
      "source": [
        "epochs = 20\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhNOKtSyUYzC"
      },
      "source": [
        "### Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjN_F4QxHIsh"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-AUR_b7UcaK"
      },
      "source": [
        "## Observations\n",
        "\n",
        "\n",
        "*   Compared to Model1, when we added the Dropouts in Model-2, we could see that Overfitting got controlled prettymuch and valication and Training accuracy are in-line.\n",
        "*   Both Training and Validation loss is same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TdDi4u-VTkW"
      },
      "source": [
        "#### Find the Class Distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAhwYgtTQRzq"
      },
      "source": [
        "path_list = [x for x in glob.glob(os.path.join(data_dir_train, '*', '*.jpg'))]\n",
        "lesion_list=[ os.path.basename(os.path.dirname(x)) for x in glob.glob(os.path.join(data_dir_train, '*', '*.jpg')) ]\n",
        "dataframe_dict = dict(zip(path_list, lesion_list))\n",
        "original_df = pd.DataFrame(list(dataframe_dict.items()),columns = ['Path','Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_df['Label'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "IFtFzHKOe9XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4csQL1dvO0b2"
      },
      "source": [
        "## Observations\n",
        "\n",
        "\n",
        "*   **seborrheic keratosis** has least number of samples.\n",
        "*   **pigmented benign keratosis** has highest number of samples.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb-stKyHPf8v"
      },
      "source": [
        "##  Rectify the class imbalance using 'Augmentor'\n",
        "\n",
        "Augmentor helps to add more samples across all classes so that none of the classes have very few samples.\n",
        "\n",
        "ref: (https://augmentor.readthedocs.io/en/master/) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItAg4rU-SzJh"
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZKzTe3zWL4O"
      },
      "source": [
        "To use `Augmentor`, the following general procedure is followed:\n",
        "\n",
        "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
        "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
        "3. Execute these operations by calling the `Pipelineâ€™s` `sample()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Egt9EHjR-Dd"
      },
      "source": [
        "path_to_training_dataset=\"/content/DataSet/Train/\"\n",
        "import Augmentor\n",
        "for i in class_names:\n",
        "    print(path_to_training_dataset + i)\n",
        "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
        "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
        "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcBIFZGbWuFa"
      },
      "source": [
        "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxWcMqZhdRWz"
      },
      "source": [
        "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
        "print(image_count_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      },
      "source": [
        "### Lets see the distribution of augmented data after adding new images to the original training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZvVdF7g3E1z"
      },
      "source": [
        "path_list_new = [x for x in glob.glob(os.path.join(data_dir_train, '*', 'output','*.jpg'))]\n",
        "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob.glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okcqVFAA2nxK"
      },
      "source": [
        "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njzBxTNT2nxK"
      },
      "source": [
        "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
        "new_df = original_df.append(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j45rmxd2nxK"
      },
      "source": [
        "df2['Label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NirFBvGPmgI"
      },
      "source": [
        "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnspeMbRWNs"
      },
      "source": [
        "#### **Todo**: Train the model on the data created using Augmentor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFcj1XgndRWz"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in path_list:\n",
        "  os.remove(file)\n"
      ],
      "metadata": {
        "id": "PF4aUQl0J-9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move output files to main class folder\n",
        "for new_path in path_list_new:\n",
        "  shutil.move(new_path,os.path.dirname(os.path.dirname(new_path))+'/'+os.path.basename(new_path))\n"
      ],
      "metadata": {
        "id": "QDCO8wRXMxn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for class_name in class_names:\n",
        "  os.chdir('/content/DataSet/Train/'+class_name)\n",
        "  os.removedirs('output')"
      ],
      "metadata": {
        "id": "hv-B3TWDRWYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0haOU11Ey8ey"
      },
      "source": [
        "####  Create a training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4ZY11judRWz"
      },
      "source": [
        "data_dir_train=\"/content/DataSet/Train\"\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwNJVDuBP5kf"
      },
      "source": [
        "####  Create a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX191d_3dRW0"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir_train,\n",
        "  seed=123,\n",
        "  validation_split = 0.2,\n",
        "  subset = 'validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaoWeOEpVjqH"
      },
      "source": [
        "#### Model3: After Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch0MuKvFVr7O"
      },
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                 input_shape=(180,180,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "# model.add(Dense(256,kernel_regularizer=l2(0.9)))\n",
        "model.add(Dense(128,kernel_regularizer=l2(0.5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5N9LxkVx1B"
      },
      "source": [
        "#### Compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H47GWmLbdRW1"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gS-Y1bJV7uy"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcV6OdI4dRW1"
      },
      "source": [
        "epochs = 50\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuvfCTsBWLMp"
      },
      "source": [
        "#### Visualize the model results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCTXwfkTdRW1"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Way4lakC4_p0"
      },
      "source": [
        "#### Observations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   After Augmentation, Accuracy got increased almost 30% from 50% to 80%  and it seems to be a good model.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}